{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217dd62c",
   "metadata": {},
   "source": [
    "# 03: Back Propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29225edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48ee4d",
   "metadata": {},
   "source": [
    "![](../img/03_forward_backward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41a7e6",
   "metadata": {},
   "source": [
    "The training loop for a neural network involves:\n",
    "\n",
    "1. A **forward pass**: Feed the input features ($x_1$, $x_2$) through all the layers of the network to compute our predictions, $\\hat{y}$.\n",
    "\n",
    "2. Compute the **loss** (or cost), $\\mathcal{L}(y, \\hat{y})$, a function of the predicted values $\\hat{y}$ and the actual values $y$.\n",
    "\n",
    "3. A **backward pass** (or _back propagation_): Feed the loss $\\mathcal{L}$ back through the network to compute the rate of change of the loss (i.e. the derivative) with respect to the network parameters (the weights and biases for each node, $w$, $b$)\n",
    "\n",
    "4. Given their derivatives, update the network parameters ($w$, $b$) using an algorithm like gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff8139",
   "metadata": {},
   "source": [
    "## Forward Pass: Recap\n",
    "\n",
    "Each node computes a linear combination of the output of all the nodes in the previous layer, for example:\n",
    "\n",
    "$$\n",
    "z_1^{[1]} = w_{1 \\rightarrow 1}^{[1]} x_1 + w_{2 \\rightarrow 1}^{[1]} x_2 + b_1^{[1]}\n",
    "$$\n",
    "\n",
    "This is passed to an activation function, $g$, (assumed to be the same function in all layers here), to create the final output, or \"activation\", of each node:\n",
    "\n",
    "$$\n",
    "a_3^{[2]} = g(z_3^{[2]})\n",
    "$$\n",
    "\n",
    "For example, $\\hat{y}$, can be expressed in terms of the activation of the final layer as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = a_1^{[3]} = g\\left(w_{1 \\rightarrow 1}^{[3]} a_{1}^{[2]} + w_{2 \\rightarrow 1}^{[3]} a_{2}^{[2]} + w_{3 \\rightarrow 1}^{[3]} a_{3}^{[2]} + b_1^{[3]}\\right)\n",
    "$$\n",
    "\n",
    "The terms not introduced above mean:\n",
    "\n",
    "- $w_{j \\rightarrow k}^{[l]}$: The weight between node $j$ in layer $l-1$ and node $k$ in layer $l$.\n",
    "- $a_k^{[l]}$: The activation of node $k$ in layer $l$\n",
    "- $b_k^{[l]}$: The bias term for node $k$ in layer $l$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3117a35",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Let's consider a simpler network, with one input, two hidden nodes, and one output:\n",
    "\n",
    "![](../img/03_backprop_example_params.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce578c66",
   "metadata": {},
   "source": [
    "Here I've also included a node after the network's output to represent the calculation of the loss, $\\mathcal{L}(y, \\hat{y})$, where $\\hat{y} = g(z_1^{[2]})$ is the predicted value from the network and $y$ the true value.\n",
    "\n",
    "This network has seven parameters: $w_1^{[1]}$, $w_2^{[1]}$, $b_1^{[1]}$, $b_2^{[1]}$, $w_1^{[2]}$, $w_2^{[2]}$, $b_1^{[2]}$\n",
    "\n",
    "In gradient descent we use the partial derivative of the loss function with respect to the parameters to update the network, making small changes to the parameters like:\n",
    "\n",
    "$$\n",
    "w_1^{[1]}  = w_1^{[1]} - \\alpha\\frac{\\partial \\mathcal{L}}{\\partial w_1^{[1]}}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the learning rate.\n",
    "\n",
    "So to perform gradient descent we need the derivatives for each parameter, i.e. we need to compute:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_1^{[1]}},\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_2^{[1]}},\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_1^{[1]}},\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_2^{[1]}},\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_1^{[2]}},\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_2^{[2]}},\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_1^{[2]}}\n",
    "$$\n",
    "\n",
    "How can we compute all those terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02243aaa",
   "metadata": {},
   "source": [
    "## Chain Rule (for derivatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac753b",
   "metadata": {},
   "source": [
    "### Case 1: $f$ is a function of $g$, and $g$ is a function of $x$\n",
    "\n",
    "$$\n",
    "f = f(g(x))\n",
    "$$\n",
    "\n",
    "The chain rule states that the derivative of $w$ with respect to $x$ is given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d}x} = \\frac{\\mathrm{d} f}{\\mathrm{d} g} \\frac{\\mathrm{d} g}{\\mathrm{d} x}\n",
    "$$\n",
    "\n",
    "#### Example\n",
    "\n",
    "Find the derivative of $f(x) = (e^x + x)^2$:\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "g(x) = e^x + x \\\\\n",
    "f(g) = g^2 \\\\\n",
    "$$\n",
    "\n",
    "Then by chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} g} = 2g \\\\\n",
    "\\frac{\\mathrm{d} g}{\\mathrm{d} x} = e^x + 1 \\\\\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d}x} = \\frac{\\mathrm{d} f}{\\mathrm{d} g} \\frac{\\mathrm{d} g}{\\mathrm{d} x} = 2g(e^x + 1) \\\\\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d}x} = 2(e^x + x)(e^x + 1) \n",
    "$$\n",
    "\n",
    "### Case 2: $f$ is a function of $g$ and $h$, which are both functions of $x$\n",
    "\n",
    "$$\n",
    "f = f(g(x), h(x))\n",
    "$$\n",
    "\n",
    "To find the derivative of $f$ with respect to $x$, the chain rule states that you must sum over its (partial) derivatives for each input ($g$, $h$):\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d}x} = \\frac{\\partial f}{\\partial g} \\frac{\\mathrm{d} g}{\\mathrm{d} x} + \\frac{\\partial f}{\\partial h} \\frac{\\mathrm{d} h}{\\mathrm{d} x}\n",
    "$$\n",
    "\n",
    "This is the _multi-variable_ chain rule.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Find the derivative of:\n",
    "\n",
    "$$\n",
    "f(x) = x^2(3x+1) - \\sin(x^2) \\\\\n",
    "$$\n",
    "\n",
    "which can be written as:\n",
    "\n",
    "$$\n",
    "f(g, h) = h g - \\sin(h) \\\\\n",
    "g(x) = 3x + 1 \\\\\n",
    "h(x) = x^2\n",
    "$$\n",
    "\n",
    "Then by chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial g} = h\\\\\n",
    "\\frac{\\mathrm{d} g}{\\mathrm{d} x} = 3 \\\\\n",
    "\\frac{\\partial f}{\\partial h} = g - \\cos(h) \\\\\n",
    "\\frac{\\mathrm{d} h}{\\mathrm{d} x} = 2x \\\\\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d}x} = \\frac{\\partial f}{\\partial g} \\frac{\\mathrm{d} g}{\\mathrm{d} x} + \\frac{\\partial f}{\\partial h} \\frac{\\mathrm{d} h}{\\mathrm{d} x} =\n",
    "3h + 2x\\left(g-\\cos(h)\\right) \\\\\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d}x} = 3x^2 + 2x\\left(3x + 1 -\\cos(x^2)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b692ea9",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "\n",
    "Here's the example network again, but with each edge (arrow) labeled by the partial derviative between the two connected nodes:\n",
    "\n",
    "![](../img/03_backprop_example_diffs.png)\n",
    "\n",
    "To compute the derivative of the loss with respect to any term in the network we can use the chain rule. Starting with the loss on the right, we move \"backwards\" through the network, multiplying the partial derivatives until we get to the term we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a14e58",
   "metadata": {},
   "source": [
    "### Example 1: Computing the gradient for $b_1^{[2]}$\n",
    "\n",
    "$$\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{blue}{\\partial b_1^{[2]}}} = \\frac{\\partial z_1^{[2]}}{\\color{blue}{\\partial b_1^{[2]}}} \\frac{\\color{green}{\\partial a_1^{[2]}}}{\\partial z_1^{[2]}} \\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{green}{\\partial a_1^{[2]}}}\n",
    "$$\n",
    "\n",
    "Log loss for one data point (remembering that $\\hat{y} = a_1^{[2]}$):\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - y \\log(a_1^{[2]}) - (1 - y)\\log(1 - a_1^{[2]}) \\\\\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{green}{\\partial a_1^{[2]}}} = -\\frac{y}{a_1^{[2]}} + \\frac{1-y}{1-a_1^{[2]}}\n",
    "$$\n",
    "\n",
    "If using a sigmoid activation function:\n",
    "\n",
    "$$\n",
    "a_1^{[2]} = \\frac{1}{1+\\exp(-z_1^{[2]})} \\\\\n",
    "\\frac{\\color{green}{\\partial a_1^{[2]}}}{\\partial z_1^{[2]}} = a_1^{[2]} (1 - a_1^{[2]})\n",
    "$$\n",
    "\n",
    "$z_1^{[2]}$ is a linear combination of its inputs:\n",
    "\n",
    "$$\n",
    "z_1^{[2]} = w_1^{[2]}a_1^{[1]} + w_2^{[2]}a_2^{[1]} + b_1^{[2]} \\\\\n",
    "\\frac{\\partial z_1^{[2]}}{\\color{blue}{\\partial b_1^{[2]}}} = 1\n",
    "$$\n",
    "\n",
    "So overall we could write the loss derivative with respect to the bias as:\n",
    "\n",
    "$$\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{blue}{\\partial b_1^{[2]}}} =\n",
    "1 . \\frac{\\color{green}{\\partial a_1^{[2]}}}{\\partial z_1^{[2]}}\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{green}{\\partial a_1^{[2]}}} =\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\partial z_1^{[2]}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7070a1",
   "metadata": {},
   "source": [
    "### Example 2: Computing the gradient for $w_2^{[1]}$\n",
    "\n",
    "$$\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{magenta}{\\partial w_2^{[1]}}} =\n",
    "\\frac{\\color{gray}{\\partial z_2^{[1]}}}{\\color{magenta}{\\partial w_2^{[1]}}}\n",
    "\\frac{\\color{orange}{\\partial a_2^{[1]}}}{\\color{gray}{\\partial z_2^{[1]}}}\n",
    "\\frac{\\partial z_1^{[2]}}{\\color{orange}{\\partial a_2^{[1]}}}\n",
    "\\frac{\\color{green}{\\partial a_1^{[2]}}}{\\partial z_1^{[2]}}\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{green}{\\partial a_1^{[2]}}}\n",
    "$$\n",
    "\n",
    "We've seen the form of all the derivatives above in the first example, except for the first term:\n",
    "\n",
    "$$\n",
    "z_2^{[1]} = w_2^{[1]}x + b_2^{[1]} \\\\\n",
    "\\frac{\\color{gray}{\\partial z_2^{[1]}}}{\\color{magenta}{\\partial w_2^{[1]}}} = x\n",
    "$$\n",
    "\n",
    "For the weights after the first layer, the inputs $x$ are replaced by node activations $a$. We can relabel $x = a_1^{[0]}$ to make the general trend clearer.\n",
    "\n",
    "The last four terms on the right side of the expression for the derivative can be simplified to $\\color{red}{\\partial \\mathcal{L}} / \\color{gray}{\\partial z_2^{[1]}}$. Then we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{magenta}{\\partial w_2^{[1]}}} =\n",
    "\\frac{\\color{gray}{\\partial z_2^{[1]}}}{\\color{magenta}{\\partial w_2^{[1]}}}\n",
    "\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{gray}{\\partial z_2^{[1]}}}\n",
    "=\n",
    "a_1^{[0]}\\frac{\\color{red}{\\partial \\mathcal{L}}}{\\color{gray}{\\partial z_2^{[1]}}}\n",
    "$$\n",
    "\n",
    "We can also compute that $\\frac{\\color{gray}{\\partial z_2^{[1]}}}{\\color{magenta}{\\partial b_2^{[1]}}} = 1$ (see example 1), so it follows that $\\frac{\\partial \\mathcal{L}}{\\partial w_2^{[1]}} =\\frac{\\partial \\mathcal{L}}{\\partial z_2^{[1]}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05774e1e",
   "metadata": {},
   "source": [
    "### Multiple Paths\n",
    "\n",
    "There is one case not covered by the simplified network and examples above - where you have multiple paths from the output (loss) back to the term of interest. Such as this:\n",
    "\n",
    "![](../img/03_backprop_multipath.png)\n",
    "\n",
    "In this case you must sum all the possible paths (this also follows from the multi-variable chain rule)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced42966",
   "metadata": {},
   "source": [
    "### Back Propagation and Efficiency\n",
    "\n",
    "It's important to note that:\n",
    "\n",
    "- The derivatives in the two examples share many terms in common (e.g. the derivative of the loss with respect to the final output)\n",
    "- Each term is a fairly simple combination of quantities that must be computed during the forward pass (like the activation values in hidden layers)\n",
    "\n",
    "These properties of back propagation form the basis for efficient implementations in major frameworks (pytorch, Tensorflow, JAX etc.), mostly via:\n",
    "\n",
    "- Matrix operations\n",
    "- Computation graphs\n",
    "- Caching intermediate values\n",
    "- Automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89377e4",
   "metadata": {},
   "source": [
    "## Computation Graphs and Auto-Differentiation\n",
    "\n",
    "In the background, large frameworks like pytorch use computation graphs and \"auto-differentiation\" to be able to compute gradients efficiently.\n",
    "\n",
    "### Example\n",
    "\n",
    "Here's an example of a simple logistic regression (one layer) network in the form of a _computation graph_:\n",
    "\n",
    "<img src=\"../img/03_computation_graph.png\" alt=\"Computation graph\" width=\"500\">\n",
    "\n",
    "- Each node represents either an input variable/parameter (white/clear background), or an operation that applies to one or more of the previously defined values. In this graph the operations are summation ($+$), multiplication ($*$), sigmoid ($g$), and log loss ($\\mathcal{L}$).\n",
    "- The values of all the nodes on a row must be known before the next row can be calculated.\n",
    "\n",
    "In the computation graph we'll store:\n",
    "\n",
    "- The relationships between all the nodes (how they are connected and the operations that are performed on them)\n",
    "- The value of each node for a given input\n",
    "- The gradient of each node for a given input, with respect to the final node\n",
    "\n",
    "Having all the node values and the relationships between the nodes let's us compute the gradient at each node efficiently:\n",
    "\n",
    "#### Forward pass\n",
    "\n",
    "When doing a forward (top to bottom) pass through the network we store the values computed at all nodes (i.e. including the intermediate values on each row):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b6587e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat = 0.6225\n",
      "L = 0.4741\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "\n",
    "# =================\n",
    "# Row 1 in diagram\n",
    "# =================\n",
    "x1 = 1.5\n",
    "x2 = 2.5\n",
    "\n",
    "w1 = -4\n",
    "w2 = 3\n",
    "\n",
    "# =================\n",
    "# Row 2 in diagram\n",
    "# =================\n",
    "w1x1 = w1 * x1\n",
    "w2x2 = w2 * x2\n",
    "\n",
    "b = -1\n",
    "\n",
    "# =================\n",
    "# Row 3 in diagram\n",
    "# =================\n",
    "z = w1x1 + w2x2 + b\n",
    "\n",
    "# =================\n",
    "# Row 4 in diagram\n",
    "# =================\n",
    "yhat = 1 / (1 + np.exp(-z))  # sigmoid\n",
    "\n",
    "y = 1\n",
    "\n",
    "# =================\n",
    "# Row 5 in diagram\n",
    "# =================\n",
    "L = -y * np.log(yhat) - (1 - y) * np.log(1 - yhat)  # log loss\n",
    "\n",
    "print(f\"yhat = {yhat:.4f}\")\n",
    "print(f\"L = {L:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e6aa1",
   "metadata": {},
   "source": [
    "#### Backward pass\n",
    "\n",
    "Now we can use the node values from the forward pass, our knowledge of the computation graph, and the chain rule to compute the gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1561380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dw1 = -0.5663\n",
      "dL_dw2 = -0.9439\n",
      "dL_db = -0.3775\n"
     ]
    }
   ],
   "source": [
    "# Backward pass\n",
    "\n",
    "# =================\n",
    "# Row 5 in diagram\n",
    "# =================\n",
    "dL_dyhat = -y / yhat + (1 - y) / (1 - yhat)  # derivative of log loss\n",
    "\n",
    "# =================\n",
    "# Row 4 in diagram\n",
    "# =================\n",
    "dyhat_dz = yhat * (1 - yhat)  # derivative of sigmoid\n",
    "\n",
    "dL_dz = dyhat_dz * dL_dyhat\n",
    "\n",
    "# =================\n",
    "# Row 3 in diagram\n",
    "# =================\n",
    "dz_dw1x1 = 1  # summation nodes pass the same gradient backwards\n",
    "dz_dw2x2 = 1  # z = w1x1 + w2x2 + b, dz/d(w2x2) = 1\n",
    "dz_db = 1\n",
    "\n",
    "dL_dw1x1 = dz_dw1x1 * dL_dz\n",
    "dL_dw2x2 = dz_dw2x2 * dL_dz\n",
    "dL_db = dz_db * dL_dz\n",
    "\n",
    "# =================\n",
    "# Row 2 in diagram\n",
    "# =================\n",
    "dw1x1_dw1 = x1  # multiplication node gradients take the value of the other node\n",
    "dw2x2_dw2 = x2  # e.g. d(w2x2) / d(w2) = x2\n",
    "\n",
    "dL_dw1 = dw1x1_dw1 * dL_dw1x1\n",
    "dL_dw2 = dw2x2_dw2 * dL_dw2x2\n",
    "\n",
    "print(f\"dL_dw1 = {dL_dw1:.4f}\")\n",
    "print(f\"dL_dw2 = {dL_dw2:.4f}\")\n",
    "print(f\"dL_db = {dL_db:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237cbd1",
   "metadata": {},
   "source": [
    "This is an extremely verbose way of representing this, we'll see matrix notation in the next section that will let us represent networks in a much more concise way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b9d4fa",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "We can manually do the same operations in pytorch and with pytorch's tensor class, being careful to:\n",
    "\n",
    "- Set `requires_grad=True` for the parameters we're interested in the gradients of (w1, w2, and b) - we'll come back to this later\n",
    "- Use torch's implementations of sigmoid (`torch.sigmoid`) and log loss (`torch.nn.functional.binary_cross_entropy`).\n",
    "\n",
    "Here's the forward pass again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd3e4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat = tensor([0.6225], grad_fn=<SigmoidBackward0>)\n",
      "L = 0.4741\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "\n",
    "# =================\n",
    "# Row 1 in diagram\n",
    "# =================\n",
    "x1 = torch.tensor([1.5], requires_grad=False)\n",
    "x2 = torch.tensor([2.5], requires_grad=False)\n",
    "\n",
    "w1 = torch.tensor([-4.0], requires_grad=True)\n",
    "w2 = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# =================\n",
    "# Row 2 in diagram\n",
    "# =================\n",
    "w1x1 = w1 * x1\n",
    "w2x2 = w2 * x2\n",
    "\n",
    "b = torch.tensor([-1.0], requires_grad=True)\n",
    "\n",
    "# =================\n",
    "# Row 3 in diagram\n",
    "# =================\n",
    "z = w1x1 + w2x2 + b\n",
    "\n",
    "# =================\n",
    "# Row 4 in diagram\n",
    "# =================\n",
    "yhat = torch.sigmoid(z)\n",
    "\n",
    "y = torch.tensor([1.0], requires_grad=False)\n",
    "\n",
    "# =================\n",
    "# Row 5 in diagram\n",
    "# =================\n",
    "L = nn.functional.binary_cross_entropy(yhat, y)\n",
    "\n",
    "print(f\"yhat = {yhat}\")\n",
    "print(f\"L = {L:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458d258f",
   "metadata": {},
   "source": [
    "Note the values are the same as our own version above.\n",
    "\n",
    "Now for the magic - in the background pytorch has built a computation graph from the variables we've defined and can compute the gradients (do a backward pass) for us automatically (for the parameters where we've specified `requires_grad=True`), as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96227ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dw1 = tensor([-0.5663])\n",
      "dL_dw2 = tensor([-0.9439])\n",
      "dL_db = tensor([-0.3775])\n"
     ]
    }
   ],
   "source": [
    "L.backward()\n",
    "\n",
    "print(f\"dL_dw1 = {w1.grad}\")\n",
    "print(f\"dL_dw2 = {w2.grad}\")\n",
    "print(f\"dL_db = {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a74cb",
   "metadata": {},
   "source": [
    "Again, these match the gradients in our own version, but with a lot fewer lines of code (for us) ðŸŽ‰\n",
    "\n",
    "You might remember seeing `.backward()` before in the linear/logistic regression notebooks - hopefully this gives you the intuition for what it's doing! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
